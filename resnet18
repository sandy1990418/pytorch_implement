import torch 
import torch.nn as nn
import torch.nn.functional as F


class bottleneck(nn.Module):
    def __init__(self,in_channel,out_channel,stride=1):
        super(bottleneck,self).init()
        self.mid_layer=nn.Sequntial(
            nn.Conv2d(in_channel,out_channel,stride,kernel_size = 3,padding=1,bias =False)
            nn.BatchNorm2d(out_channel),
            nn.ReLU(inplace =True),
            nn.Conv2d(in_channel,out_channel,stride=1,kernel_size = 3,padding=1,bias =False),
            nn.BatchNorm2d(out_channel)
        )
        self.shortcut = self.Squential()
        if stride !=1 or in_channel != out_channel:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channel,out_channel,stride,kernel_size = 3,padding=1,bias =False)
                nn.BatchNorm2d(out_channel)
                )
            

        def forward(self,x):
            x = self.mid_layer(x)
            out = x+self.shortcut(x)
            out = F.ReLU(out)
            return out 
        



class ResNet50(nn.Module):
    def __init__(self,bottleneck,num_classes):
        super(ResNet50, self).init()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2,padding = 3)
        self.batch = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        
        self.max_pooling1 = nn.MaxPool2d(3, stride=2)
        self.layer1 = self.make_layer(bottleneck,64,2,1)
        self.layer2 = self.make_layer(bottleneck,128,2,2)
        self.layer3 = self.make_layer(bottleneck,256,2,2)
        self.layer4 = self.make_layer(bottleneck,512,2,2)
        self.fc = nn.Linear(512,num_classes)

    
    ## combine layers 
    def make_layer(self,bottleneck,use_channel,number_iteration,stride):
        ## create list (append and create list)
        strides = [stride]+[1]*(numer_iteration-1)
        ## create empty list
        layers =[]
        for stride in strides:
            layers.append(bottelneck(self.in_channel,use_channel,stride))
            self.in_channel = use_channel
        return nn.Sequential(*layers)
    
    def forward(self,x):
        x = self.relu(self.batch(self.conv1(x)))
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = F.avg_pool2d(x,4)      
        x = x.view(x.size(0), -1)
        x = self.fc(x)

        return x 


    



