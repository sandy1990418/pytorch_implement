import torch 
import torch.nn as nn
import torch.nn.functional as F


class bottleneck(nn.Module):
    def __init__(self,in_channel,out_channel,stride=1):
        super(bottleneck,self).init()
        self.mid_layer=nn.Sequntial(
            nn.Conv2d(in_channel,out_channel,stride,kernel_size = 3,padding=1,bias =False)
            nn.BatchNorm2d(out_channel),
            nn.ReLU(inplace =True),
            nn.Conv2d(in_channel,out_channel,stride=1,kernel_size = 3,padding=1,bias =False),
            nn.BatchNorm2d(out_channel)
        )
        self.shortcut = self.Squential()
        if stride !=1 or in_channel != out_channel:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channel,out_channel,stride,kernel_size = 3,padding=1,bias =False)
                nn.BatchNorm2d(out_channel))
            

        def forward(self,x):
            x = self.mid_layer(x)
            out = x+self.shortcut(x)
            out = F.ReLU(out)
            return out 
        



        



class ResNet50(nn.Module):
    def __init__(self):
        super(ResNet50, self).init()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2,padding = 3)
        #nn.MaxPool2d(3, stride=2)
        self.model = nn.Sequential(
            nn.Conv2d()
        )


        model = nn.Sequential(
            nn.Conv2d(1,20,5),
            nn.ReLU(),
            nn.Conv2d(20,64,5),
            nn.ReLU()
            )
    
    ## combine layers 
    def make_layer(self,bottleneck,use_channel,number_iteration,stride):
        ## create list (append and create list)
        strides = [stride]+[1]*(numer_iteration-1)
        ## create empty list
        layers =[]
        for stride in strides:
            layers.append(bottelneck(self.in_channel,use_channel,stride))
            self.in_channel = use_channel
        return nn.Sequential(*layers)
    



